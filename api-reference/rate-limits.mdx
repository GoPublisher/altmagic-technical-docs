---
title: 'Rate Limits'
description: 'Understand rate limiting policies and how to handle rate limit responses'
---

# Rate Limits

The Alt Magic API implements rate limiting to ensure fair usage and maintain service quality for all users. Understanding these limits is crucial for building robust integrations.

## Overview

Rate limiting prevents abuse and ensures all users have access to our services. Limits are applied per user (identified by `user_id`) or per IP address if no user ID is provided.

## Rate Limit Tiers

### Standard Plan
- **Limit**: 100 requests per minute
- **Burst**: Up to 200 requests in a single minute (with cooldown)
- **Window**: Rolling 1-minute window

### Pro Plan
- **Limit**: 500 requests per minute
- **Burst**: Up to 1000 requests in a single minute (with cooldown)
- **Window**: Rolling 1-minute window

### Enterprise Plan
- **Limit**: Custom limits based on agreement
- **Burst**: Negotiated burst capacity
- **Window**: Rolling 1-minute window

## How Rate Limiting Works

### 1. Request Counting

- Each API request counts toward your rate limit
- Limits are tracked in real-time
- Counts reset every minute on a rolling basis

### 2. Identification Methods

**Primary**: `user_id` parameter in request body
**Fallback**: IP address if no user ID provided

### 3. Rate Limit Headers

Every response includes rate limit information:

```http
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 95
X-RateLimit-Reset: 1640995200
X-RateLimit-Reset-Time: 2022-01-01T00:00:00Z
```

## Rate Limit Responses

### 429 Too Many Requests

When you exceed the rate limit:

```json
{
  "error": "rate_limit_exceeded",
  "message": "Too many requests from this User, please try again later.",
  "retry_after": 60,
  "limit": 100,
  "reset_time": "2024-01-15T10:30:00Z"
}
```

### Response Fields

| Field | Description |
|-------|-------------|
| `error` | Error type identifier |
| `message` | Human-readable error message |
| `retry_after` | Seconds to wait before retrying |
| `limit` | Your current rate limit |
| `reset_time` | When the rate limit resets |

## Handling Rate Limits

### 1. Implement Exponential Backoff

```javascript
async function makeRequestWithRetry(data, maxRetries = 3) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch('https://api.altmagic.pro/api-alt-text', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-api-key': API_KEY
        },
        body: JSON.stringify(data)
      });

      if (response.status === 429) {
        const errorData = await response.json();
        const waitTime = errorData.retry_after || Math.pow(2, attempt) * 1000;
        
        console.log(`Rate limited. Waiting ${waitTime}ms before retry ${attempt}`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        continue;
      }

      return await response.json();
    } catch (error) {
      if (attempt === maxRetries) throw error;
      console.log(`Request failed, retrying... (${attempt}/${maxRetries})`);
    }
  }
}
```

### 2. Python Implementation

```python
import time
import requests
from requests.exceptions import RequestException

def make_request_with_retry(data, max_retries=3):
    for attempt in range(1, max_retries + 1):
        try:
            response = requests.post(
                'https://api.altmagic.pro/api-alt-text',
                headers={
                    'Content-Type': 'application/json',
                    'x-api-key': API_KEY
                },
                json=data
            )
            
            if response.status_code == 429:
                error_data = response.json()
                wait_time = error_data.get('retry_after', 2 ** attempt)
                
                print(f"Rate limited. Waiting {wait_time}s before retry {attempt}")
                time.sleep(wait_time)
                continue
                
            return response.json()
            
        except RequestException as e:
            if attempt == max_retries:
                raise e
            print(f"Request failed, retrying... ({attempt}/{max_retries})")
```

### 3. cURL with Retry Logic

```bash
#!/bin/bash

make_request() {
    local max_retries=3
    local attempt=1
    
    while [ $attempt -le $max_retries ]; do
        response=$(curl -s -w "%{http_code}" -X POST "https://api.altmagic.pro/api-alt-text" \
            -H "Content-Type: application/json" \
            -H "x-api-key: $API_KEY" \
            -d '{
                "image_url": "https://example.com/image.jpg",
                "user_id": "user@example.com"
            }')
        
        http_code="${response: -3}"
        body="${response%???}"
        
        if [ "$http_code" = "429" ]; then
            retry_after=$(echo "$body" | jq -r '.retry_after // 60')
            echo "Rate limited. Waiting ${retry_after}s before retry ${attempt}"
            sleep "$retry_after"
            attempt=$((attempt + 1))
            continue
        fi
        
        echo "$body"
        return 0
    done
    
    echo "Max retries exceeded"
    return 1
}
```

## Best Practices

### 1. Monitor Rate Limit Headers

Always check the rate limit headers to understand your current usage:

```javascript
const response = await fetch(url, options);
const remaining = response.headers.get('X-RateLimit-Remaining');
const resetTime = response.headers.get('X-RateLimit-Reset-Time');

console.log(`Requests remaining: ${remaining}`);
console.log(`Rate limit resets at: ${resetTime}`);
```

### 2. Implement Queuing for High-Volume Applications

```javascript
class RateLimitQueue {
  constructor(maxConcurrent = 10) {
    this.queue = [];
    this.running = 0;
    this.maxConcurrent = maxConcurrent;
  }

  async add(requestFn) {
    return new Promise((resolve, reject) => {
      this.queue.push({ requestFn, resolve, reject });
      this.process();
    });
  }

  async process() {
    if (this.running >= this.maxConcurrent || this.queue.length === 0) {
      return;
    }

    this.running++;
    const { requestFn, resolve, reject } = this.queue.shift();

    try {
      const result = await requestFn();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.running--;
      this.process();
    }
  }
}
```

### 3. Use Different User IDs for Parallel Processing

If you need to process multiple images simultaneously, consider using different user IDs:

```javascript
const userIds = ['user1@example.com', 'user2@example.com', 'user3@example.com'];
const requests = imageUrls.map((url, index) => ({
  image_url: url,
  user_id: userIds[index % userIds.length]
}));
```

## Monitoring and Alerts

### 1. Track Rate Limit Usage

```javascript
class RateLimitMonitor {
  constructor() {
    this.usage = new Map();
  }

  trackRequest(userId) {
    const now = Date.now();
    const minute = Math.floor(now / 60000);
    
    if (!this.usage.has(userId)) {
      this.usage.set(userId, new Map());
    }
    
    const userUsage = this.usage.get(userId);
    const currentCount = userUsage.get(minute) || 0;
    userUsage.set(minute, currentCount + 1);
    
    // Clean up old entries
    for (const [key] of userUsage) {
      if (key < minute - 5) {
        userUsage.delete(key);
      }
    }
  }

  getCurrentUsage(userId) {
    const now = Date.now();
    const minute = Math.floor(now / 60000);
    const userUsage = this.usage.get(userId);
    return userUsage ? (userUsage.get(minute) || 0) : 0;
  }
}
```

### 2. Set Up Alerts

```javascript
const monitor = new RateLimitMonitor();

// Check usage before making requests
if (monitor.getCurrentUsage(userId) > 80) {
  console.warn(`High rate limit usage for ${userId}: ${monitor.getCurrentUsage(userId)}/100`);
}
```

## Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **Unexpected 429 errors** | Check if you're using the correct user ID |
| **Rate limits too low** | Consider upgrading to Pro or Enterprise plan |
| **Burst requests failing** | Implement proper queuing and throttling |
| **IP-based limiting** | Always provide a user_id in your requests |

### Getting Help

If you're experiencing rate limiting issues:

1. **Check your current plan** and rate limits
2. **Review your request patterns** for potential optimization
3. **Contact support** if you need higher limits for legitimate use cases
